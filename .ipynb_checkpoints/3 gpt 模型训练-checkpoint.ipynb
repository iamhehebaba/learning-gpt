{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c649be2-c58d-41c8-98ed-8db90b575efa",
   "metadata": {},
   "source": [
    "# GPT2 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70be856e-6a04-4e04-9b36-b56a2f00ca8c",
   "metadata": {},
   "source": [
    "# 1 训练数据加工\n",
    "# 2 GPT2 模型\n",
    "# 3 模型训练\n",
    "# 4 模型推理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180f560b-c2c6-4411-a19b-84fa581120a0",
   "metadata": {},
   "source": [
    "# 1 训练数据加工\n",
    "## 数据来源：https://modelscope.cn/datasets/mapjack/openwebtextSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aa54aea-3247-4795-bff3-5ce55f3254ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 arrow files.\n",
      "torch.Size([32, 128]) torch.Size([32, 128])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import tiktoken\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "# 设置参数\n",
    "num_proc = 14\n",
    "\n",
    "local_data_path=\"/Users/wangaijun/pythoncode/github/model/openwebtext\"\n",
    "\n",
    "block_size = 128  # 根据你的模型设置合适的块大小\n",
    "batch_size = 32  # 根据你的硬件设置合适的批次大小\n",
    "device_type = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device_type)\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "def process(example):\n",
    "    ids = enc.encode_ordinary(example['text'])\n",
    "    ids.append(enc.eot_token)\n",
    "    return {'ids': ids, 'len': len(ids)}\n",
    "\n",
    "class StreamingParquetDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, data_files, split, block_size, num_proc=14):\n",
    "        self.data_files = data_files\n",
    "        self.split = split\n",
    "        self.block_size = block_size\n",
    "        self.num_proc = num_proc\n",
    "        self.dataset = load_dataset(\"arrow\", data_files={split: data_files}, streaming=True)\n",
    "        self.tokenized = self.dataset[split].map(process, remove_columns=['text'])\n",
    "    def __iter__(self):\n",
    "        for example in self.tokenized:\n",
    "            ids = example['ids']\n",
    "            for i in range(0, len(ids) - self.block_size, self.block_size):\n",
    "                x = torch.tensor(ids[i:i + self.block_size], dtype=torch.int64)\n",
    "                y = torch.tensor(ids[i + 1:i + 1 + self.block_size], dtype=torch.int64)\n",
    "                yield x, y\n",
    "\n",
    "# 配置路径和文件\n",
    "\n",
    "arrow_files = [os.path.join(local_data_path, f) for f in os.listdir(local_data_path) if f.endswith('.arrow')]\n",
    "print(f\"Found {len(arrow_files)} arrow files.\")\n",
    "\n",
    "# 创建数据集\n",
    "train_dataset = StreamingParquetDataset(arrow_files, 'train', block_size, num_proc)\n",
    "val_dataset = StreamingParquetDataset([arrow_files[-1]], 'val', block_size, num_proc)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# 示例函数：获取一个批次的数据\n",
    "def get_batch(loader, device):\n",
    "    for x, y in loader:\n",
    "        if device_type == 'cuda':\n",
    "            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        else:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "        yield x, y\n",
    "\n",
    "# 使用示例\n",
    "for x, y in get_batch(train_loader, device):\n",
    "    # 在这里进行模型训练\n",
    "    print(x.shape, y.shape)\n",
    "    break  # 只打印一个批次的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "781fb4e0-0ef4-4299-905b-fb288badbd63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4303,    40,  7156,  ...,   356,   423,  1760],\n",
       "         [  523,  1290,  5818,  ...,   661,   423,  3724],\n",
       "         [   13,  1148,   612,  ..., 31309,   262, 10768],\n",
       "         ...,\n",
       "         [   13,   198,   198,  ...,    11,  5434, 30013],\n",
       "         [27425,   290, 22771,  ...,  3003,   422,  4955],\n",
       "         [ 6718,  1010,   284,  ...,    87,   737,  1629]]),\n",
       " tensor([[   40,  7156,  3698,  ...,   423,  1760,   523],\n",
       "         [ 1290,  5818,   470,  ...,   423,  3724,    13],\n",
       "         [ 1148,   612,  1223,  ...,   262, 10768,  5471],\n",
       "         ...,\n",
       "         [  198,   198,    37,  ...,  5434, 30013, 27425],\n",
       "         [  290, 22771,   737,  ...,   422,  4955,  6718],\n",
       "         [ 1010,   284, 13586,  ...,   737,  1629, 24897]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75fae68-c89b-4738-9d96-b343a1e43d4f",
   "metadata": {},
   "source": [
    "# 2 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2758ea00-f759-4d5b-9a30-9bff450218f0",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"images/transformer.png\" alt=\"Image\" style=\"width:600px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "726d8cb5-faf8-4f2f-a228-12cd28f4a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "class config:\n",
    "    block_size=1024\n",
    "    vocab_size=50304\n",
    "    n_layer=12\n",
    "    n_head=12\n",
    "    n_embd=768\n",
    "    dropout=0.0\n",
    "    bias=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e44fb8-e6b1-496f-be03-d14e6043a5be",
   "metadata": {},
   "source": [
    "## 2.1 Embedding和位置编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60288ee3-a2b6-4234-9b2d-9af190914f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "wte = nn.Embedding(config.vocab_size, config.n_embd)\n",
    "wpe = nn.Embedding(config.block_size, config.n_embd)\n",
    "drop = nn.Dropout(config.dropout)\n",
    "ln_f = nn.LayerNorm(config.n_embd, bias=config.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45eda222-5901-4b82-ade9-c32b96e5821e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embd=wte(x)\n",
    "x_embd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e295147-ba75-4ed3-b9a9-7c8671728abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_embd_ln=ln_f(x_embd)\n",
    "x_embd_ln.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b471e8-2879-41f5-aefe-bef8142ad731",
   "metadata": {},
   "source": [
    "## 2.2 线性层-保持形状不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5837699b-09cd-4bfc-9f34-cb32098562ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
    "        self.gelu    = nn.GELU()\n",
    "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7494648-c905-49dd-9a47-bcb7dc9d6ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp=MLP(config)(x_embd_ln)\n",
    "mlp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2376857a-4fac-4d06-abe8-fece9c6695a9",
   "metadata": {},
   "source": [
    "## 2.3 因果自注意"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a470a65-c384-4e30-b4e7-943aaf0d021b",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"images/multiheadattention.png\" alt=\"Image\" style=\"width:500px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6f1ed82-6e70-4485-ab45-a259f9ff84ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
    "        # regularization\n",
    "        self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        self.resid_dropout = nn.Dropout(config.dropout)\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.dropout = config.dropout\n",
    "        # flash attention make GPU go brrrrr but support is only in PyTorch >= 2.0\n",
    "        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n",
    "        if not self.flash:\n",
    "            print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n",
    "            # causal mask to ensure that attention is only applied to the left in the input sequence\n",
    "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                        .view(1, 1, config.block_size, config.block_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "\n",
    "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
    "        if self.flash:\n",
    "            # efficient attention using Flash Attention CUDA kernels\n",
    "            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)\n",
    "        else:\n",
    "            # manual implementation of attention\n",
    "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "            att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
    "            att = F.softmax(att, dim=-1)\n",
    "            att = self.attn_dropout(att)\n",
    "            y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "\n",
    "        # output projection\n",
    "        y = self.resid_dropout(self.c_proj(y))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6acc99-97d6-435c-a11d-f55f01372ff0",
   "metadata": {},
   "source": [
    "#### 构造因果mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8f6a82b-f847-47c5-b292-eafa2abdb1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask matric:\n",
      "tensor([[[[1., 0., 0., 0.],\n",
      "          [1., 1., 0., 0.],\n",
      "          [1., 1., 1., 0.],\n",
      "          [1., 1., 1., 1.]]]])\n",
      "att score \n",
      "tensor([[[1.2386, 0.9562, 0.8730, 0.9235],\n",
      "         [0.9562, 1.2590, 1.0642, 1.0390],\n",
      "         [0.8730, 1.0642, 1.2794, 1.1148],\n",
      "         [0.9235, 1.0390, 1.1148, 1.2704]]])\n",
      "mask  att \n",
      "tensor([[[[1.2386,   -inf,   -inf,   -inf],\n",
      "          [0.9562, 1.2590,   -inf,   -inf],\n",
      "          [0.8730, 1.0642, 1.2794,   -inf],\n",
      "          [0.9235, 1.0390, 1.1148, 1.2704]]]])\n"
     ]
    }
   ],
   "source": [
    "mask=torch.tril(torch.ones(4, 4)) .view(1, 1, 4, 4)\n",
    "print(\"mask matric:\")\n",
    "print(mask)\n",
    "q=k=v=torch.rand(1,4,10)\n",
    "att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "print(\"att score \")\n",
    "print(att)\n",
    "mask_att = att.masked_fill(mask[:,:,:4,:4] == 0, float('-inf'))\n",
    "print(\"mask  att \")\n",
    "print(mask_att)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a50b28d-f4ce-47a5-a824-b297c6b3f246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CausalSelfAttention(config)(torch.rand(1,4,768)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6d8073f-f549-4e07-9ed0-78205f962c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "atten=CausalSelfAttention(config)(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04c35124-ff9c-4f97-85cc-792885b6e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 =  nn.LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 =  nn.LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5dd099e-579e-4944-9f85-64dd48c07db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block=Block(config)(atten)\n",
    "block.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "028b95dc-8be5-4aa2-891f-bdf5ad224ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = nn.ModuleList([Block(config) for _ in range(config.n_layer)])\n",
    "lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8695c90d-01ff-4b1a-b1f1-d0afdb15b84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lm_head' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wte\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m \u001b[43mlm_head\u001b[49m\u001b[38;5;241m.\u001b[39mweight\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lm_head' is not defined"
     ]
    }
   ],
   "source": [
    "wte.weight = lm_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74fd8053-b65d-41bf-974a-55cf555efb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0356, -0.0050,  0.0183,  ..., -0.0172, -0.0040, -0.0155],\n",
       "        [ 0.0327, -0.0345, -0.0253,  ..., -0.0176,  0.0301, -0.0296],\n",
       "        [ 0.0280, -0.0002,  0.0315,  ...,  0.0187, -0.0221,  0.0136],\n",
       "        ...,\n",
       "        [ 0.0083, -0.0109,  0.0299,  ..., -0.0106,  0.0268,  0.0111],\n",
       "        [-0.0019,  0.0262,  0.0063,  ...,  0.0139, -0.0037,  0.0250],\n",
       "        [ 0.0244,  0.0199,  0.0329,  ..., -0.0263,  0.0264,  0.0120]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wte.weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c843ebb-0063-4320-9b6c-26efe9e58eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0356, -0.0050,  0.0183,  ..., -0.0172, -0.0040, -0.0155],\n",
       "        [ 0.0327, -0.0345, -0.0253,  ..., -0.0176,  0.0301, -0.0296],\n",
       "        [ 0.0280, -0.0002,  0.0315,  ...,  0.0187, -0.0221,  0.0136],\n",
       "        ...,\n",
       "        [ 0.0083, -0.0109,  0.0299,  ..., -0.0106,  0.0268,  0.0111],\n",
       "        [-0.0019,  0.0262,  0.0063,  ...,  0.0139, -0.0037,  0.0250],\n",
       "        [ 0.0244,  0.0199,  0.0329,  ..., -0.0263,  0.0264,  0.0120]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_head.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47be6f9-d861-4047-9c46-739e004f02c8",
   "metadata": {},
   "source": [
    "### 模型综合应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab38884d-4e5e-4580-91ac-baa5badb9d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer=nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            drop = nn.Dropout(config.dropout),\n",
    "            bloks = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = nn.LayerNorm(config.n_embd, bias=config.bias),\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c0a863f-a0b2-4017-8e39-7d0df8eec19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 参数计算\n",
    "transformer.wpe.weight.numel()# 1024*768\n",
    "torch.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b84d7c53-b7f8-4a52-8d15-e8f32b928eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_emb shape: torch.Size([32, 128, 768]) x_pos torch.Size([128, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 768])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_emb=transformer.wte(x)\n",
    "x_pos=transformer.wpe(torch.arange(x.shape[1]))\n",
    "print(\"x_emb shape:\",x_emb.shape,\"x_pos\",x_pos.shape)\n",
    "x_emb_pos=transformer.drop(x_pos+x_emb)\n",
    "x_emb_pos.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "915e4379-b8aa-4c64-8aac-07dfe792b0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 768])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_x=x_emb_pos\n",
    "for block in transformer.bloks:\n",
    "    block_x=block(block_x)\n",
    "block_x.shape   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3ffd86e-2243-4a11-ad42-dc79d2a94f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 768])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_x_ln=transformer.ln_f(block_x)\n",
    "block_x_ln.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f29364-5a2d-4ec5-bc1c-4ffc2ec92031",
   "metadata": {},
   "source": [
    "# 3 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed6d61c1-742d-470d-aff2-b840aebf58d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 50304])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = lm_head(block_x_ln)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1678132f-4d84-425a-bf47-e3be532c5fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.9796, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "targets=y\n",
    "loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b452d0-2664-4dcd-b47d-a432af682669",
   "metadata": {},
   "source": [
    "#### 补充 cross_entropy和NLLLoss计算损失"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1d427c-d7c2-42ad-9ade-00c7db848160",
   "metadata": {},
   "source": [
    "#### F.cross_entropy 是 PyTorch 中用于计算交叉熵损失的函数，它通常被用来评估分类模型的性能。这个函数内部已经包含了对预测值进行 log_softmax 的步骤，所以你不需要在输入到 F.cross_entropy 之前手动对预测值进行 softmax 或 log_softmax 处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f6ef7fe-0883-4ad8-b2aa-56d24429dce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict\n",
      "tensor([[0.2956, 0.2771, 0.1637, 0.2688, 0.2839],\n",
      "        [0.3973, 0.9177, 0.9226, 0.7005, 0.3502],\n",
      "        [0.9846, 0.2220, 0.2206, 0.4623, 0.8314]])\n",
      "y\n",
      "tensor([4, 0, 3])\n",
      "en_loss: 1.7416986227035522\n"
     ]
    }
   ],
   "source": [
    "length=3\n",
    "number_of_label=5\n",
    "predict=torch.rand(length,number_of_label)\n",
    "y_fake=torch.randint(0,number_of_label,(length,))\n",
    "\n",
    "en_loss=F.cross_entropy(predict,y_fake, ignore_index=-1)\n",
    "print(\"predict\")\n",
    "print(predict)\n",
    "print(\"y\")\n",
    "print(y_fake)\n",
    "print(\"en_loss:\", en_loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e26bf305-48e2-4c43-8b1b-9ad10a1369b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.7416986227035522\n"
     ]
    }
   ],
   "source": [
    "# 应用 log_softmax\n",
    "log_probs = F.log_softmax(predict, dim=1)\n",
    "# 创建 NLLLoss 函数实例\n",
    "nll_loss = nn.NLLLoss()\n",
    "# 计算负对数似然损失\n",
    "loss = nll_loss(log_probs, y_fake)\n",
    "print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8298496-aa49-4814-8441-021006481f30",
   "metadata": {},
   "source": [
    "# 4 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1203189-1d64-4f1a-8606-6a5667c08525",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.vocab_size is not None\n",
    "        assert config.block_size is not None\n",
    "        self.config = config\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            drop = nn.Dropout(config.dropout),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = nn.LayerNorm(config.n_embd, bias=config.bias),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        # with weight tying when using torch.compile() some warnings get generated:\n",
    "        # \"UserWarning: functional_call was passed multiple values for tied weights.\n",
    "        # This behavior is deprecated and will be an error in future versions\"\n",
    "        # not 100% sure what this is, so far seems to be harmless. TODO investigate\n",
    "        self.transformer.wte.weight = self.lm_head.weight # https://paperswithcode.com/method/weight-tying\n",
    "\n",
    "        # init all weights\n",
    "        self.apply(self._init_weights)\n",
    "        # apply special scaled init to the residual projections, per GPT-2 paper\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
    "\n",
    "        # report number of parameters\n",
    "        print(\"number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n",
    "\n",
    "    def get_num_params(self, non_embedding=True):\n",
    "        \"\"\"\n",
    "        Return the number of parameters in the model.\n",
    "        For non-embedding count (default), the position embeddings get subtracted.\n",
    "        The token embeddings would too, except due to the parameter sharing these\n",
    "        params are actually used as weights in the final layer, so we include them.\n",
    "        \"\"\"\n",
    "        n_params = sum(p.numel() for p in self.parameters())\n",
    "        if non_embedding:\n",
    "            n_params -= self.transformer.wpe.weight.numel()\n",
    "        return n_params\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        device = idx.device\n",
    "        b, t = idx.size()\n",
    "        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n",
    "        pos = torch.arange(0, t, dtype=torch.long, device=device) # shape (t)\n",
    "\n",
    "        # forward the GPT model itself\n",
    "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
    "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (t, n_embd)\n",
    "        x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "        \n",
    "        if targets is not None:\n",
    "            # if we are given some desired targets also calculate the loss\n",
    "            logits = self.lm_head(x)\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "        else:\n",
    "            # inference-time mini-optimization: only forward the lm_head on the very last position\n",
    "            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim\n",
    "            loss = None\n",
    "\n",
    "        return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b528629-b8e6-41ac-9eeb-3eca397e3344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4db723e2-6a3c-43c4-a376-aa3491509285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 123.59M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(50304, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (c_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_model=GPT(config)\n",
    "gpt2_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7535611f-c789-4f98-92ba-74a1382bad6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0233,  0.0126, -0.0055, -0.0283,  0.0163],\n",
       "        [-0.0210,  0.0059, -0.0161,  0.0175,  0.0436],\n",
       "        [-0.0007,  0.0309,  0.0204,  0.0337, -0.0349]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adamw optimizer\n",
    "learning_rate = 6e-4 # max learning rate\n",
    "max_iters = 600000 # total number of training iterations\n",
    "weight_decay = 1e-1\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "grad_clip = 1.0 # clip gradients at this value, or disable if == 0.0\n",
    "optimizer = torch.optim.AdamW(gpt2_model.parameters(), lr=learning_rate, betas=(beta1,beta2))\n",
    "\n",
    "gpt2_model.transformer.wte.weight[:3,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7090a65-e447-473c-9399-c7770a74e130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128]) torch.Size([32, 128])\n",
      "embedding weight step 0 tensor([[ 0.0233,  0.0126, -0.0055, -0.0283,  0.0163],\n",
      "        [-0.0210,  0.0059, -0.0161,  0.0175,  0.0436],\n",
      "        [-0.0007,  0.0309,  0.0204,  0.0337, -0.0349]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([32, 128]) torch.Size([32, 128])\n",
      "embedding weight step 1 tensor([[ 0.0227,  0.0120, -0.0061, -0.0289,  0.0169],\n",
      "        [-0.0215,  0.0053, -0.0167,  0.0169,  0.0442],\n",
      "        [-0.0013,  0.0303,  0.0198,  0.0331, -0.0343]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([32, 128]) torch.Size([32, 128])\n",
      "embedding weight step 2 tensor([[ 0.0229,  0.0114, -0.0067, -0.0294,  0.0173],\n",
      "        [-0.0213,  0.0047, -0.0173,  0.0164,  0.0446],\n",
      "        [-0.0016,  0.0297,  0.0192,  0.0326, -0.0338]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([32, 128]) torch.Size([32, 128])\n",
      "embedding weight step 3 tensor([[ 0.0225,  0.0117, -0.0063, -0.0290,  0.0170],\n",
      "        [-0.0216,  0.0048, -0.0169,  0.0168,  0.0443],\n",
      "        [-0.0014,  0.0291,  0.0187,  0.0321, -0.0333]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 使用示例\n",
    "i=0\n",
    "for x, y in get_batch(train_loader, device):\n",
    "    optimizer.zero_grad()  # 清零梯度\n",
    "    # 在这里进行模型训练\n",
    "    print(x.shape, y.shape)\n",
    "    print(f\"embedding weight step {i}\",gpt2_model.transformer.wte.weight[:3,:5])\n",
    "    logits, loss = gpt2_model(x, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i==3:\n",
    "        break  # 只打印一个批次的数据\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c921c89-dfdf-44fb-bdaa-9f04c5b8959c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c86887d0-9966-46ed-9bd6-d6c0a2f4d5c1",
   "metadata": {},
   "source": [
    "# 5 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01aff2c2-377f-4288-8d4c-125a50f24b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3448, 6908, 2513, 6145],\n",
       "        [ 617, 7403, 9165, 8417]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_new_tokens=30\n",
    "temperature=1.0\n",
    "top_k=41\n",
    "idx=torch.randint(0,10000,(2,4))\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d630bdf6-1218-4b13-8baf-f781a8c8853d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits torch.Size([2, 1, 50304])\n",
      "logits with temperature torch.Size([2, 50304])\n",
      "fake data tensor([[0., 2., 3., 5., 7., 7., 6., 3.],\n",
      "        [5., 5., 5., 1., 2., 6., 2., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-inf, -inf, -inf, 5., 7., 7., 6., -inf],\n",
       "        [5., 5., 5., -inf, -inf, 6., -inf, -inf]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits, _ = gpt2_model(idx)\n",
    "print(\"logits\",logits.shape)\n",
    "logits = logits[:, -1, :] / temperature\n",
    "print(\"logits with temperature\",logits.shape)\n",
    "\n",
    "# 测试topk\n",
    "logits=torch.randint(0,10,(2,8),dtype=torch.float32)\n",
    "print(\"fake data\",logits)\n",
    "if top_k is not None:\n",
    "    v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "    logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6716669-e2d1-4415-8ff9-d7c2e1cf4608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3448, 6908, 2513, 6145,  262,  262,  262,  262,  262,   11,   11,  262,\n",
       "          262,   13,  262,  262,  262,   13,   13,   13,   13,  262,   11,  262,\n",
       "           13,  262,   13,  262,   11,  262,   11,  262,  262,   13],\n",
       "        [ 617, 7403, 9165, 8417,   13,   11,   11,  262,  262,   11,   13,  262,\n",
       "          262,  262,  262,  262,  262,  262,  262,  262,  262,  262,   11,   11,\n",
       "           13,   11,   13,  262,   13,  198,  198,  262,   13,  262]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for _ in range(max_new_tokens):\n",
    "        logits, _ = gpt2_model(idx)\n",
    "        logits = logits[:, -1, :] / temperature\n",
    "        # optionally crop the logits to only the top k options\n",
    "        if top_k is not None:\n",
    "            v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "            logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "        # apply softmax to convert logits to (normalized) probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        # sample from the distribution\n",
    "        idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        # append sampled index to the running sequence and continue\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e1be677-092e-471f-9f57-104550ea1a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode = lambda l: enc.decode(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4916aa66-27a3-4714-a45c-e4fc8066b94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pri trick walk marg the the the the the,, the the. the the the.... the, the. the. the, the, the the.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 解码\n",
    "decode(idx[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a269f27-0935-486c-85b4-74061078b3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "torch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
