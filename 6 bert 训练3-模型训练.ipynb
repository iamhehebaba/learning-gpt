{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32aaf1ee-fa87-421c-a93c-5e4496f2e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert.bert_model import BertModel\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from transformers import BertTokenizer\n",
    "input_path=\"./data/bert_output_data2.json\"\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = []\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                self.data.append(data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(item[\"input_ids\"]),\n",
    "            \"input_mask\": torch.tensor(item[\"input_mask\"]),\n",
    "            \"segment_ids\": torch.tensor(item[\"segment_ids\"]),\n",
    "            \"masked_lm_ids\": torch.tensor(item[\"masked_lm_ids\"]),\n",
    "            \"masked_lm_positions\": torch.tensor(item[\"masked_lm_positions\"]),\n",
    "            \"masked_lm_weights\": torch.tensor(item[\"masked_lm_weights\"]),\n",
    "            \"next_sentence_labels\": torch.tensor(item[\"next_sentence_labels\"])\n",
    "        }\n",
    "\n",
    "class BertConfig:\n",
    "    def __init__(self, vocab_size, hidden_size=144, num_hidden_layers=3, num_attention_heads=12,\n",
    "                 intermediate_size=512, hidden_act='gelu', hidden_dropout_prob=0.1,\n",
    "                 attention_probs_dropout_prob=0.1, max_position_embeddings=512,\n",
    "                 type_vocab_size=2, initializer_range=0.02):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.hidden_act = hidden_act\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.hidden_dropout_prob = hidden_dropout_prob\n",
    "        self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.type_vocab_size = type_vocab_size\n",
    "        self.initializer_range = initializer_range\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24bb185b-4102-434a-8f1f-06d4358a589e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512])\n",
      "torch.Size([32, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 4777,  782,  ..., 1912,  769,  102],\n",
       "         [ 101, 3688, 3813,  ...,  712, 2476,  102],\n",
       "         [ 101, 1062, 1066,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 6432, 1168,  ...,    0,    0,    0],\n",
       "         [ 101,  677,  103,  ...,    0,    0,    0],\n",
       "         [ 101, 4638, 2356,  ..., 1171,  520,  102]]),\n",
       " 'input_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 1, 1, 1]]),\n",
       " 'segment_ids': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 1, 1, 1]]),\n",
       " 'masked_lm_ids': tensor([[3136, 1187, 1447, 2157, 4777, 4955, 4060, 2533,  511,  511,  511, 1054,\n",
       "           833, 1447, 3341, 4638, 6789, 3341, 2456,  704],\n",
       "         [ 511, 6821, 1068, 1925,  704,  712, 2340,  697, 3189, 6205, 1359, 3341,\n",
       "          1104, 7151, 1066, 8024, 1298, 1139, 4664, 1066],\n",
       "         [7231, 8160, 6809, 2968, 6981, 4128, 1403, 6774, 1220, 2600, 1285, 2825,\n",
       "          2968, 8024, 6586, 4764, 1469, 1351, 1079,  511],\n",
       "         [4638, 1139,  671, 1158, 2658,  749, 7360, 8024,  852, 6874, 1139, 2956,\n",
       "          3791, 3326, 8032, 7557,  683, 1862, 3221, 1744],\n",
       "         [3793, 1161, 2590, 2190, 8024, 2533, 1730, 1169, 7368, 2399,  127, 1744,\n",
       "          5739, 4060, 1054, 3696,  749,  673, 6848, 1925],\n",
       "         [ 511, 6598, 2207, 7028, 7216, 6206, 8024, 2357,  897, 3291, 4638, 6848,\n",
       "           711, 3918, 7216, 4638, 3680, 6121,  689,  511],\n",
       "         [8363,  100,  100, 1092, 3175, 1824, 6206, 2397,  782, 8024, 2398, 1322,\n",
       "           754, 4794, 1054, 3124,  818, 6381, 2408,  511],\n",
       "         [5722, 4993, 5468, 6206, 8024, 4873, 1199, 7027,  671, 2809,  782, 1862,\n",
       "          2466, 1395, 6929,  511,  800, 1469, 1291,  704],\n",
       "         [2832, 7216, 6084, 2466, 2902, 3621, 8024, 3417,  678, 2544, 2990, 1218,\n",
       "          3221,  821, 1290, 1071, 4761, 4638, 3680, 4636],\n",
       "         [2262, 6432, 8024,  677, 8188, 2399, 3791, 2137, 8038,  862, 8043,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [1469, 1153, 8024, 3621, 1772, 7372, 5445, 6814, 7583,  886, 6598, 1920,\n",
       "          1105, 3221,  511, 8038, 4500, 1501, 4307,  511],\n",
       "         [ 886,  702, 1355, 2357, 8024, 1762, 1372,  955, 7599,  852, 4651, 2768,\n",
       "          7900,  511, 3457, 5285, 1073,  510,  692, 5309],\n",
       "         [5722, 4638, 2466, 3144, 4276, 1372,  128, 2972,  100,  868, 5445, 3749,\n",
       "          6237,  100,  100,  100, 8024,  100,  100,  100],\n",
       "         [1348,  800,  738, 4995, 6371, 1542, 1447, 6150, 7368, 1146, 4638, 6716,\n",
       "           511, 7008, 3198, 3300, 2376, 6413, 8024, 4638],\n",
       "         [2399, 3341, 6587, 7028,  809, 1378, 2533, 1400, 1139,  928, 2400, 6437,\n",
       "           726, 8024, 4638,  809,  671, 2398, 6814, 1039],\n",
       "         [2772, 3326, 6435, 4638, 2418, 4638, 4509,  782, 1164, 3326, 6835, 8025,\n",
       "           782, 8024, 2902, 1164, 8038, 6418, 4509, 6435],\n",
       "         [5307, 3221, 2885, 6206, 8043, 2190, 2137, 1469,  966, 6587, 7770, 1469,\n",
       "          3419,  678, 4873,  966, 1963,  812,  812,  510],\n",
       "         [4680, 5290,  782, 4919, 4802,  769, 2496, 4415, 3696, 2137, 1104,  782,\n",
       "          3326, 2772, 1394, 4995, 2400, 4667, 3791, 1398],\n",
       "         [5739, 1092,  671, 2408, 1762, 6764, 1780, 1346,  511, 3299,  704, 7339,\n",
       "          1765, 5273, 8024, 1925, 4788, 1744, 6226,  683],\n",
       "         [ 711, 6947, 2336,  511,  671, 4266, 7025,  120, 8039, 6132, 3351, 1798,\n",
       "          1139, 5401, 3698, 6195, 4638, 5515,  511,  677],\n",
       "         [ 752, 2845, 1361,  818, 2773, 4372, 4886, 6592,  511, 2519, 2900, 7463,\n",
       "          1462, 7339, 1298, 3189, 6858,  704, 6809, 1506],\n",
       "         [7555, 3837, 4684, 2137, 7555, 1168, 5277,  511, 6587, 4680, 6598, 6574,\n",
       "          2487, 6444, 7309, 2418, 7557, 7481, 1392, 5390],\n",
       "         [1814,  684, 3613, 4638, 2577, 5307,  511, 1079, 1071, 1378, 2772,  924,\n",
       "          4955, 4638, 5632, 1355, 3566, 8024,  718, 2094],\n",
       "         [4708, 1184, 2689, 1914, 4212, 6848, 6443,  881, 6422, 3796, 4125, 7755,\n",
       "          6944, 7676, 2458, 5517, 8024, 1377,  683, 7030],\n",
       "         [8205,  782,  807, 6848, 1999,  868, 4638, 8024,  517,  511, 1068,  704,\n",
       "          1059, 6375, 4638, 2798,  833, 3635, 2399, 3299],\n",
       "         [1079, 1062,  722, 5445, 6890, 7361, 1164, 8024, 1744, 3318, 8024, 5865,\n",
       "          4638, 4507, 2496, 8020, 8024, 1072, 1358, 8020],\n",
       "         [1146, 8024, 2137, 4638, 3309,  769, 2398, 1920, 1378,  671, 3309,  955,\n",
       "          4906, 3613, 1355, 2357, 8024,  100, 1217, 6379],\n",
       "         [3696, 1380, 3209, 2229, 3583, 1999,  511, 1092, 4638, 6808, 2514, 1059,\n",
       "          1265, 6393, 6449, 7270, 1156,  749, 3118, 4906],\n",
       "         [6134,  749, 2399,  697, 4638, 6392, 6574, 4638, 1939, 3791, 2137,  976,\n",
       "           754, 2141, 4638, 6821, 6448, 4862, 1282, 1920],\n",
       "         [1168, 6226, 3297, 3297, 1290, 1305, 5296, 4692, 2792, 3341,  757,  741,\n",
       "           868, 6121, 5966,  517, 1305, 1762, 2399, 2814],\n",
       "         [4638, 8038, 1420,  800, 4955, 4994,  784,  720, 6887, 1266, 4638, 4862,\n",
       "           677, 8024, 6820, 6929, 3698, 7556,  686,  100],\n",
       "         [1825,  511, 4638, 2229,  704, 2768, 8108, 1999,  807, 1765, 3845, 6392,\n",
       "           809, 7484, 1086, 3022, 1849, 1849, 5529, 4851]]),\n",
       " 'masked_lm_positions': tensor([[ 32,  55,  83, 120, 139, 140, 293, 306, 311, 329, 343, 379, 387, 398,\n",
       "          425, 429, 443, 454, 502, 507],\n",
       "         [ 40,  45,  49, 123, 163, 172, 181, 184, 216, 260, 263, 272, 286, 295,\n",
       "          311, 331, 400, 439, 446, 481],\n",
       "         [  8,  75,  96, 119, 201, 205, 222, 223, 253, 258, 307, 339, 350, 368,\n",
       "          396, 446, 460, 469, 486, 488],\n",
       "         [  5,  11,  21,  30,  42,  61,  74,  78,  79,  86,  91, 102, 131, 138,\n",
       "          157, 183, 193, 223, 230, 234],\n",
       "         [  3,  24,  74, 150, 159, 161, 221, 269, 308, 312, 313, 320, 339, 375,\n",
       "          395, 454, 472, 489, 499, 502],\n",
       "         [ 17,  28,  52,  61,  70,  74,  79,  80,  90,  96, 100, 101, 105, 117,\n",
       "          121, 122, 123, 136, 137, 154],\n",
       "         [ 39,  69,  72,  91, 113, 116, 138, 141, 157, 163, 198, 226, 240, 283,\n",
       "          315, 342, 351, 363, 365, 377],\n",
       "         [  1,  22,  27,  39,  73,  83, 109, 125, 145, 151, 173, 214, 242, 296,\n",
       "          328, 348, 378, 439, 443, 484],\n",
       "         [  6,  20,  22,  25,  36,  41,  42,  44,  50,  53,  56,  61,  68,  77,\n",
       "           87,  89,  91,  95, 102, 108],\n",
       "         [  2,   3,   4,   6,   9,  10,  20,  35,  42,  44,  52,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0],\n",
       "         [  8,  12,  13,  16,  18,  29,  88, 104, 108, 110, 127, 157, 175, 190,\n",
       "          192, 199, 201, 208, 211, 235],\n",
       "         [ 18,  35,  40,  41,  46,  47,  58,  88,  93,  96, 118, 158, 161, 165,\n",
       "          176, 194, 197, 214, 215, 216],\n",
       "         [ 14,  76,  97, 124, 132, 139, 141, 146, 197, 207, 218, 310, 325, 357,\n",
       "          367, 398, 439, 440, 470, 501],\n",
       "         [ 70,  76,  77, 135, 197, 212, 225, 234, 270, 279, 340, 341, 343, 370,\n",
       "          372, 436, 438, 443, 444, 454],\n",
       "         [  5,   7,  20,  29,  38,  43,  54,  66,  74,  86,  94, 107, 143, 151,\n",
       "          158, 163, 212, 218, 229, 232],\n",
       "         [  5,  41,  73,  79,  83, 109, 126, 128, 131, 132, 150, 154, 187, 224,\n",
       "          226, 235, 254, 258, 261, 262],\n",
       "         [ 11,  36,  63, 143, 144, 180, 201, 202, 228, 282, 364, 373, 378, 388,\n",
       "          425, 459, 461, 474, 480, 504],\n",
       "         [ 11,  67,  95, 105, 122, 129, 162, 225, 232, 271, 281, 293, 413, 423,\n",
       "          441, 473, 475, 477, 478, 507],\n",
       "         [  2,   4,   7,  18,  24,  29,  37, 101, 104, 106, 125, 140, 150, 172,\n",
       "          190, 198, 204, 207, 234, 247],\n",
       "         [ 98, 118, 170, 181, 194, 197, 215, 236, 257, 290, 311, 344, 347, 362,\n",
       "          366, 393, 412, 414, 462, 498],\n",
       "         [ 19,  94, 192, 195, 199, 207, 230, 236, 273, 359, 366, 372, 400, 408,\n",
       "          418, 441, 459, 476, 500, 502],\n",
       "         [  7,  42,  52,  55,  60,  65,  75,  85,  90,  95, 109, 110, 115, 116,\n",
       "          159, 171, 181, 184, 222, 235],\n",
       "         [ 36,  43,  45,  76,  87, 105, 150, 162, 191, 217, 239, 291, 295, 319,\n",
       "          340, 385, 435, 453, 482, 499],\n",
       "         [  2,   6,  17,  51,  66,  78,  81,  83,  91, 122, 146, 150, 164, 166,\n",
       "          169, 170, 171, 196, 208, 297],\n",
       "         [  8,  43,  45, 108, 119, 189, 246, 258, 262, 271, 298, 339, 340, 356,\n",
       "          363, 365, 377, 381, 434, 436],\n",
       "         [ 19,  42,  59,  74, 124, 157, 162, 167, 168, 203, 237, 242, 320, 334,\n",
       "          381, 400, 416, 439, 442, 477],\n",
       "         [ 12,  15,  37,  40,  60,  72,  78,  95, 101, 107, 110, 118, 140, 168,\n",
       "          169, 170, 173, 209, 226, 237],\n",
       "         [ 36,  47,  49,  66,  79, 119, 158, 215, 229, 262, 273, 318, 336, 404,\n",
       "          438, 463, 488, 495, 497, 510],\n",
       "         [  9,  10, 134, 159, 164, 174, 178, 181, 223, 239, 253, 317, 343, 351,\n",
       "          363, 410, 414, 463, 488, 495],\n",
       "         [  2,  31,  33,  46,  48,  63,  65,  67,  71,  76,  78,  89,  94, 100,\n",
       "          114, 115, 120, 121, 135, 143],\n",
       "         [  2,   6,  20,  37,  38,  39,  41,  42,  55,  82, 106, 107, 125, 157,\n",
       "          173, 180, 194, 201, 218, 223],\n",
       "         [ 40,  42,  79, 117, 136, 143, 149, 197, 216, 248, 257, 259, 265, 351,\n",
       "          365, 366, 428, 429, 439, 508]]),\n",
       " 'masked_lm_weights': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.]]),\n",
       " 'next_sentence_labels': tensor([1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "         0, 0, 0, 1, 1, 0, 0, 0])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_dataset = MyDataset(input_path)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "for data in train_loader:\n",
    "    data\n",
    "    break\n",
    "print(data[\"input_ids\"].shape)\n",
    "print(data[\"input_mask\"].shape)\n",
    "input_ids=data[\"input_ids\"]\n",
    "token_type_ids=data[\"segment_ids\"]\n",
    "attention_mask=data[\"input_mask\"]\n",
    "masked_lm_positions=data[\"masked_lm_positions\"]\n",
    "masked_lm_ids=data[\"masked_lm_ids\"]\n",
    "masked_lm_weights=data[\"masked_lm_weights\"]\n",
    "next_sentence_labels=data[\"next_sentence_labels\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d2dc2d-2829-4521-8b23-e6d770e13fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff869672-c270-4630-ae58-c7f56b495a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_indexes(sequence_tensor, positions):\n",
    "    sequence_shape = list(sequence_tensor.shape)\n",
    "    batch_size = sequence_shape[0]\n",
    "    seq_length = sequence_shape[1]\n",
    "    width = sequence_shape[2]\n",
    "\n",
    "    flat_offsets = torch.arange(0, batch_size, dtype=torch.int64).reshape(-1, 1) * seq_length\n",
    "    flat_positions = (positions + flat_offsets).reshape(-1)\n",
    "    flat_sequence_tensor = sequence_tensor.reshape(batch_size * seq_length, width)\n",
    "    output_tensor = flat_sequence_tensor[flat_positions]\n",
    "    return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daf3df02-2e51-47b2-9c7d-974a1338e642",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6192, 0.9202, 0.4370, 0.6178, 0.1265, 0.6543, 0.1944, 0.4210,\n",
      "          0.7286, 0.3453],\n",
      "         [0.2426, 0.7143, 0.2243, 0.8417, 0.8804, 0.9084, 0.6356, 0.0085,\n",
      "          0.1740, 0.3323],\n",
      "         [0.9957, 0.7029, 0.5443, 0.8433, 0.4333, 0.3006, 0.3595, 0.1784,\n",
      "          0.7058, 0.1251],\n",
      "         [0.1414, 0.8563, 0.4120, 0.5211, 0.9991, 0.1006, 0.6647, 0.1092,\n",
      "          0.6681, 0.2601],\n",
      "         [0.3065, 0.9432, 0.5592, 0.3568, 0.4359, 0.0126, 0.4728, 0.3069,\n",
      "          0.4900, 0.6574],\n",
      "         [0.5425, 0.8609, 0.2502, 0.6821, 0.8000, 0.2218, 0.9561, 0.6038,\n",
      "          0.9912, 0.1466]],\n",
      "\n",
      "        [[0.3784, 0.5543, 0.0117, 0.9622, 0.2962, 0.3833, 0.5392, 0.0209,\n",
      "          0.2235, 0.2522],\n",
      "         [0.9660, 0.6147, 0.1299, 0.3373, 0.6129, 0.8223, 0.4620, 0.8901,\n",
      "          0.4853, 0.2207],\n",
      "         [0.3283, 0.0312, 0.1678, 0.6374, 0.2692, 0.1102, 0.8474, 0.3824,\n",
      "          0.9538, 0.2237],\n",
      "         [0.8582, 0.1526, 0.0985, 0.8792, 0.8305, 0.0206, 0.9023, 0.0195,\n",
      "          0.2873, 0.7935],\n",
      "         [0.2463, 0.7037, 0.1734, 0.1034, 0.3955, 0.5412, 0.5027, 0.8275,\n",
      "          0.3670, 0.1580],\n",
      "         [0.1993, 0.7979, 0.3765, 0.3066, 0.0966, 0.6415, 0.7462, 0.3115,\n",
      "          0.9905, 0.2307]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.6192, 0.9202, 0.4370, 0.6178, 0.1265, 0.6543, 0.1944, 0.4210, 0.7286,\n",
       "         0.3453],\n",
       "        [0.1414, 0.8563, 0.4120, 0.5211, 0.9991, 0.1006, 0.6647, 0.1092, 0.6681,\n",
       "         0.2601],\n",
       "        [0.5425, 0.8609, 0.2502, 0.6821, 0.8000, 0.2218, 0.9561, 0.6038, 0.9912,\n",
       "         0.1466],\n",
       "        [0.3784, 0.5543, 0.0117, 0.9622, 0.2962, 0.3833, 0.5392, 0.0209, 0.2235,\n",
       "         0.2522],\n",
       "        [0.8582, 0.1526, 0.0985, 0.8792, 0.8305, 0.0206, 0.9023, 0.0195, 0.2873,\n",
       "         0.7935],\n",
       "        [0.1993, 0.7979, 0.3765, 0.3066, 0.0966, 0.6415, 0.7462, 0.3115, 0.9905,\n",
       "         0.2307]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_=torch.rand(2,6,10)\n",
    "positions=torch.tensor([0,3,5])#torch.arange(10)\n",
    "print(input_)\n",
    "gather_indexes(input_,positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2997307c-7448-4e36-ad2c-a38002a169ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 144]) torch.Size([32, 512, 144]) 3\n",
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(21128, 144)\n",
      "    (position_embeddings): Embedding(512, 144)\n",
      "    (token_type_embeddings): Embedding(2, 144)\n",
      "    (LayerNorm): LayerNorm((144,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-2): 3 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (key): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (value): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=144, out_features=144, bias=True)\n",
      "            (LayerNorm): LayerNorm((144,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (mlp): FFN(\n",
      "          (dense1): Linear(in_features=144, out_features=512, bias=True)\n",
      "          (dense2): Linear(in_features=512, out_features=144, bias=True)\n",
      "          (LayerNorm): LayerNorm((144,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=144, out_features=144, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('/Users/wangaijun/pythoncode/github/model/bert-base-chinese')\n",
    "vocab_words = list(tokenizer.vocab.keys())\n",
    "config=BertConfig(len(vocab_words))\n",
    "config.vocab_size\n",
    "bert_model = BertModel(config)x\n",
    "\n",
    "pooled_output, sequence_output, encoded_layers=bert_model(input_ids,token_type_ids,attention_mask)\n",
    "print(pooled_output.shape,sequence_output.shape,len(encoded_layers))\n",
    "print(bert_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717545e2-8309-4a74-9e3d-3fbaacd1707b",
   "metadata": {},
   "source": [
    "# 2 mask预测损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d181a54-a6a5-43b6-bd7c-038450dcee0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2038427-3df5-483d-b203-99b26fa900bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masked_lm_output(bert_config, input_tensor, output_weights, positions, label_ids, label_weights):\n",
    "    input_tensor = gather_indexes(input_tensor, positions)\n",
    "    sequential = nn.Sequential(\n",
    "        nn.Linear(bert_config.hidden_size, bert_config.hidden_size),\n",
    "        nn.LayerNorm(bert_config.hidden_size),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "    input_tensor = sequential(input_tensor)  # 使用sequential处理input_tensor\n",
    "    output_bias = nn.Parameter(torch.zeros(bert_config.vocab_size))\n",
    "    logits = torch.matmul(input_tensor, output_weights.transpose(0, 1)) + output_bias\n",
    "    log_probs = nn.functional.log_softmax(logits, dim=-1)\n",
    "\n",
    "    label_ids = label_ids.reshape(-1)\n",
    "    label_weights = label_weights.reshape(-1)\n",
    "    one_hot_labels = torch.nn.functional.one_hot(label_ids, num_classes=bert_config.vocab_size).float()\n",
    "    per_example_loss = -torch.sum(log_probs * one_hot_labels, dim=-1)\n",
    "    numerator = torch.sum(label_weights * per_example_loss)\n",
    "    denominator = torch.sum(label_weights) + 1e-5\n",
    "    loss = numerator / denominator\n",
    "\n",
    "    return loss, per_example_loss, log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02eac8b9-28f0-4240-bf35-30d5bdb5202d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.76128387451172"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm_loss, _, _ = get_masked_lm_output(config, sequence_output, bert_model.embeddings.word_embeddings.weight,\n",
    "                                            masked_lm_positions, masked_lm_ids, masked_lm_weights)\n",
    "masked_lm_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22af781-f142-4585-b5ce-541fc9d8a0e5",
   "metadata": {},
   "source": [
    "## 3 是否下一个句子损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5612bb7-7f73-40bc-a6ea-c9ce74816a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_sentence_output(bert_config, input_tensor, labels):\n",
    "    output_weights = nn.Parameter(torch.randn(2, bert_config.hidden_size))\n",
    "    output_bias = nn.Parameter(torch.zeros(2))\n",
    "    logits = torch.matmul(input_tensor, output_weights.transpose(0, 1)) + output_bias\n",
    "    log_probs = nn.functional.log_softmax(logits, dim=-1)\n",
    "    labels = labels.reshape(-1)\n",
    "    one_hot_labels = torch.nn.functional.one_hot(labels, num_classes=2).float()\n",
    "    per_example_loss = -torch.sum(one_hot_labels * log_probs, dim=-1)\n",
    "    loss = torch.mean(per_example_loss)\n",
    "    return loss, per_example_loss, log_probs\n",
    "next_sentence_loss, _, _ = get_next_sentence_output(config, pooled_output, next_sentence_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07b45550-d632-410f-a655-1c34707190a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9306, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_sentence_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9e43e4-61f3-4cd4-b24e-aaae08c9fbfa",
   "metadata": {},
   "source": [
    "# 4 损失及优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cb2ff8a-5d36-4a1a-b550-99e0847fb28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(37.6919, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = masked_lm_loss + next_sentence_loss\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f46185dc-e8ff-4fdd-ba05-318afcf3cce5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(bert_model.parameters(), lr=5e-4)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53acd741-a92e-4697-a0b1-a4df660729f0",
   "metadata": {},
   "source": [
    "# 5 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddd31162-90ae-45d5-9cbb-d3ddbf234ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding weight step 0 tensor([[-1.1905, -0.4920,  0.4736,  0.7318, -1.4121],\n",
      "        [-2.1571,  1.3470,  0.6932, -0.5502, -0.8680],\n",
      "        [ 0.7587, -1.1549, -0.5255, -0.2983,  0.1872]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "embedding weight step 1 tensor([[-1.1905, -0.4920,  0.4736,  0.7318, -1.4121],\n",
      "        [-2.1571,  1.3470,  0.6932, -0.5502, -0.8680],\n",
      "        [ 0.7587, -1.1549, -0.5255, -0.2983,  0.1872]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "embedding weight step 2 tensor([[-1.1905, -0.4920,  0.4736,  0.7318, -1.4121],\n",
      "        [-2.1571,  1.3470,  0.6932, -0.5502, -0.8680],\n",
      "        [ 0.7587, -1.1549, -0.5255, -0.2983,  0.1872]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "embedding weight step 3 tensor([[-1.1905, -0.4920,  0.4736,  0.7318, -1.4121],\n",
      "        [-2.1571,  1.3470,  0.6932, -0.5502, -0.8680],\n",
      "        [ 0.7587, -1.1549, -0.5255, -0.2983,  0.1872]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "embedding weight step 3 tensor([[-1.1905, -0.4920,  0.4736,  0.7318, -1.4121],\n",
      "        [-2.1571,  1.3470,  0.6932, -0.5502, -0.8680],\n",
      "        [ 0.7587, -1.1549, -0.5255, -0.2983,  0.1872]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "embedding weight step 3 tensor([[-1.1905, -0.4920,  0.4736,  0.7318, -1.4121],\n",
      "        [-2.1571,  1.3470,  0.6932, -0.5502, -0.8680],\n",
      "        [ 0.7587, -1.1549, -0.5255, -0.2983,  0.1872]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "embedding weight step 3 tensor([[-1.1905, -0.4920,  0.4736,  0.7318, -1.4121],\n",
      "        [-2.1571,  1.3470,  0.6932, -0.5502, -0.8680],\n",
      "        [ 0.7587, -1.1549, -0.5255, -0.2983,  0.1872]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=5\n",
    "i=0\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in train_loader:\n",
    "        input_ids=data[\"input_ids\"]\n",
    "        token_type_ids=data[\"segment_ids\"]\n",
    "        attention_mask=data[\"input_mask\"]\n",
    "        masked_lm_positions=data[\"masked_lm_positions\"]\n",
    "        masked_lm_ids=data[\"masked_lm_ids\"]\n",
    "        masked_lm_weights=data[\"masked_lm_weights\"]\n",
    "        next_sentence_labels=data[\"next_sentence_labels\"]\n",
    "        optimizer.zero_grad()\n",
    "        pooled_output, sequence_output, encoded_layers=bert_model(input_ids,token_type_ids,attention_mask)\n",
    "        masked_lm_loss, _, _ = get_masked_lm_output(config, sequence_output, bert_model.embeddings.word_embeddings.weight,\n",
    "                                            masked_lm_positions, masked_lm_ids, masked_lm_weights)\n",
    "        next_sentence_loss, _, _ = get_next_sentence_output(config, pooled_output, next_sentence_labels)\n",
    "        loss = masked_lm_loss + next_sentence_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"embedding weight step {i}\",bert_model.embeddings.word_embeddings.weight[:3,:5])\n",
    "        if i>=3:\n",
    "            break\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aab373c-2d8d-4167-ae49-d4a290f78c4c",
   "metadata": {},
   "source": [
    "# 6 模型保存与加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c9feeda-1e57-4bd4-9d76-f6bb4d46dd37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(21128, 144)\n",
       "    (position_embeddings): Embedding(512, 144)\n",
       "    (token_type_embeddings): Embedding(2, 144)\n",
       "    (LayerNorm): LayerNorm((144,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-2): 3 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=144, out_features=144, bias=True)\n",
       "            (key): Linear(in_features=144, out_features=144, bias=True)\n",
       "            (value): Linear(in_features=144, out_features=144, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=144, out_features=144, bias=True)\n",
       "            (LayerNorm): LayerNorm((144,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (mlp): FFN(\n",
       "          (dense1): Linear(in_features=144, out_features=512, bias=True)\n",
       "          (dense2): Linear(in_features=512, out_features=144, bias=True)\n",
       "          (LayerNorm): LayerNorm((144,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=144, out_features=144, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(bert_model.state_dict(), 'bert_model.pth')\n",
    "\n",
    "# 模型加载\n",
    "tokenizer = BertTokenizer.from_pretrained('/Users/wangaijun/pythoncode/github/model/bert-base-chinese')\n",
    "vocab_words = list(tokenizer.vocab.keys())\n",
    "config=BertConfig(len(vocab_words))\n",
    "model = BertModel(config)\n",
    "model.load_state_dict(torch.load('bert_model.pth'))\n",
    "model.eval()  # 切换到评估模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1268bd1f-180b-41c1-a7a3-5ae2c35f060d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 144])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_output, sequence_output, encoded_layers=model(input_ids,token_type_ids,attention_mask)\n",
    "pooled_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aebbeba-afe0-4cf1-a296-c1a0343c521e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "torch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
