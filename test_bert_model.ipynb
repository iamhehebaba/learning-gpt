{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ef6f7e4-94f9-4bfa-ae78-b14cc3b21e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "input_path=\"./data/bert_output_data2.json\"\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = []\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                self.data.append(data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(item[\"input_ids\"]),\n",
    "            \"input_mask\": torch.tensor(item[\"input_mask\"]),\n",
    "            \"segment_ids\": torch.tensor(item[\"segment_ids\"]),\n",
    "            \"masked_lm_ids\": torch.tensor(item[\"masked_lm_ids\"]),\n",
    "            \"masked_lm_positions\": torch.tensor(item[\"masked_lm_positions\"]),\n",
    "            \"masked_lm_weights\": torch.tensor(item[\"masked_lm_weights\"]),\n",
    "            \"next_sentence_labels\": torch.tensor(item[\"next_sentence_labels\"])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a3a0d4-7a1d-4565-b3f8-daae0b6fb2d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512])\n",
      "torch.Size([8, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 7931, 2496,  ...,    0,    0,    0],\n",
       "         [ 101, 6432, 1168,  ...,    0,    0,    0],\n",
       "         [ 101, 6656,  103,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101,  103,  511,  ..., 1744, 7354,  102],\n",
       "         [ 101, 6228, 3680,  ...,    0,    0,    0],\n",
       "         [ 101, 8024, 1146,  ..., 8024, 6206,  102]]),\n",
       " 'input_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 1, 1, 1]]),\n",
       " 'segment_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 1, 1, 1]]),\n",
       " 'masked_lm_ids': tensor([[7676, 5546, 2458, 8024, 4850, 1103, 5442, 7831, 3384, 3297, 8220,  704,\n",
       "          1227, 4171, 2466, 7883, 3022, 6843,  683, 1545],\n",
       "         [1168, 6226, 3297, 3297, 1290, 1305, 5296, 4692, 2792, 3341,  757,  741,\n",
       "           868, 6121, 5966,  517, 1305, 1762, 2399, 2814],\n",
       "         [4708, 1184, 2689, 1914, 4212, 6848, 6443,  881, 6422, 3796, 4125, 7755,\n",
       "          6944, 7676, 2458, 5517, 8024, 1377,  683, 7030],\n",
       "         [5722, 4638, 2466, 3144, 4276, 1372,  128, 2972,  100,  868, 5445, 3749,\n",
       "          6237,  100,  100,  100, 8024,  100,  100,  100],\n",
       "         [2772, 3326, 6435, 4638, 2418, 4638, 4509,  782, 1164, 3326, 6835, 8025,\n",
       "           782, 8024, 2902, 1164, 8038, 6418, 4509, 6435],\n",
       "         [5722, 4993, 5468, 6206, 8024, 4873, 1199, 7027,  671, 2809,  782, 1862,\n",
       "          2466, 1395, 6929,  511,  800, 1469, 1291,  704],\n",
       "         [ 511, 6598, 2207, 7028, 7216, 6206, 8024, 2357,  897, 3291, 4638, 6848,\n",
       "           711, 3918, 7216, 4638, 3680, 6121,  689,  511],\n",
       "         [1814,  684, 3613, 4638, 2577, 5307,  511, 1079, 1071, 1378, 2772,  924,\n",
       "          4955, 4638, 5632, 1355, 3566, 8024,  718, 2094]]),\n",
       " 'masked_lm_positions': tensor([[  6,   9,  57,  69,  73,  78,  97, 119, 182, 205, 265, 274, 278, 293,\n",
       "          297, 309, 354, 377, 385, 473],\n",
       "         [  2,  31,  33,  46,  48,  63,  65,  67,  71,  76,  78,  89,  94, 100,\n",
       "          114, 115, 120, 121, 135, 143],\n",
       "         [  2,   6,  17,  51,  66,  78,  81,  83,  91, 122, 146, 150, 164, 166,\n",
       "          169, 170, 171, 196, 208, 297],\n",
       "         [ 14,  76,  97, 124, 132, 139, 141, 146, 197, 207, 218, 310, 325, 357,\n",
       "          367, 398, 439, 440, 470, 501],\n",
       "         [  5,  41,  73,  79,  83, 109, 126, 128, 131, 132, 150, 154, 187, 224,\n",
       "          226, 235, 254, 258, 261, 262],\n",
       "         [  1,  22,  27,  39,  73,  83, 109, 125, 145, 151, 173, 214, 242, 296,\n",
       "          328, 348, 378, 439, 443, 484],\n",
       "         [ 17,  28,  52,  61,  70,  74,  79,  80,  90,  96, 100, 101, 105, 117,\n",
       "          121, 122, 123, 136, 137, 154],\n",
       "         [ 36,  43,  45,  76,  87, 105, 150, 162, 191, 217, 239, 291, 295, 319,\n",
       "          340, 385, 435, 453, 482, 499]]),\n",
       " 'masked_lm_weights': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1.]]),\n",
       " 'next_sentence_labels': tensor([1, 0, 0, 0, 1, 0, 0, 1])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = MyDataset(input_path)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "for data in train_loader:\n",
    "    data\n",
    "    break\n",
    "print(data[\"input_ids\"].shape)\n",
    "print(data[\"input_mask\"].shape)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "949f3bac-8fe8-4fc3-8565-83596fbcc14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21128"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BertConfig:\n",
    "    def __init__(self, vocab_size, hidden_size=768, num_hidden_layers=12, num_attention_heads=12,\n",
    "                 intermediate_size=3072, hidden_act='gelu', hidden_dropout_prob=0.1,\n",
    "                 attention_probs_dropout_prob=0.1, max_position_embeddings=512,\n",
    "                 type_vocab_size=2, initializer_range=0.02):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.hidden_act = hidden_act\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.hidden_dropout_prob = hidden_dropout_prob\n",
    "        self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.type_vocab_size = type_vocab_size\n",
    "        self.initializer_range = initializer_range\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('/Users/wangaijun/pythoncode/github/model/bert-base-chinese')\n",
    "vocab_words = list(tokenizer.vocab.keys())\n",
    "config=BertConfig(len(vocab_words))\n",
    "config.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d305aa6-8716-436d-a66a-91d4fc3eea31",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"images/transformer.png\" alt=\"Image\" style=\"width:600px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3d759e-734a-4212-95f2-ea535d7f334e",
   "metadata": {},
   "source": [
    "# 2.1 Embedding层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00c52009-05f3-4151-a74a-ec389fb8b06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([8, 512]) token_type_ids shape torch.Size([8, 512])\n"
     ]
    }
   ],
   "source": [
    "input_ids=data[\"input_ids\"]\n",
    "token_type_ids=data[\"segment_ids\"]\n",
    "print(\"input_ids shape:\",input_ids.shape,\"token_type_ids shape\",token_type_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11c5b6bc-64d3-4df5-bf47-a2ecebe451d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512, 768]) torch.Size([512, 768]) torch.Size([8, 512, 768])\n"
     ]
    }
   ],
   "source": [
    "word_embeddings = nn.Embedding(21128, config.hidden_size)\n",
    "position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
    "\n",
    "token_emb=word_embeddings(input_ids)\n",
    "position_emb=position_embeddings(torch.arange(input_ids.shape[1], dtype=torch.long, device=input_ids.device))\n",
    "sentence_emb=token_type_embeddings(token_type_ids)\n",
    "\n",
    "print(token_emb.shape,position_emb.shape,sentence_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67254d1f-dfa4-4014-817a-64fdaee73bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEmbeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertEmbeddings, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size)\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None):\n",
    "        seq_length = input_ids.size(1)\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)\n",
    "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros_like(input_ids)\n",
    "\n",
    "        words_embeddings = self.word_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
    "\n",
    "        embeddings = words_embeddings + position_embeddings + token_type_embeddings\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c27c0684-68c8-4564-89fd-37a9d14dc670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512, 768])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embModel=BertEmbeddings(config)\n",
    "x_emb=embModel(input_ids,token_type_ids)\n",
    "x_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9310f22-a819-4c80-ae73-63cd3c09ec3a",
   "metadata": {},
   "source": [
    "# 2.2 attention 层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ae4e105-9216-4996-b04c-2325c9d7b0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512, 768]) torch.Size([8, 512, 768]) torch.Size([8, 512, 768])\n",
      "torch.Size([8, 12, 512, 64]) torch.Size([8, 12, 512, 64]) torch.Size([8, 12, 512, 64])\n"
     ]
    }
   ],
   "source": [
    "c_attn = nn.Linear(config.hidden_size, 3 * config.hidden_size)\n",
    "# q,k,v 都来自于x \n",
    "q, k, v  = c_attn(x_emb).split(config.hidden_size, dim=2)\n",
    "print(q.shape,k.shape,v.shape)\n",
    "B,T,C=x_emb.shape\n",
    "# 给q,k,v 增加head\n",
    "q = q.view(B, T, config.num_attention_heads, C // config.num_attention_heads).transpose(1, 2) # (B, nh, T, hs)\n",
    "k = k.view(B, T, config.num_attention_heads, C // config.num_attention_heads).transpose(1, 2) # (B, nh, T, hs)\n",
    "v = v.view(B, T, config.num_attention_heads, C // config.num_attention_heads).transpose(1, 2) # (B, nh, T, hs)\n",
    "print(q.shape,k.shape,v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "173ff0a6-97b1-47a9-8e9b-63e2fecfb682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_scores shape : torch.Size([8, 12, 512, 512])\n",
      "attention_mask shape : torch.Size([8, 1, 1, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512, 768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "attention_scores = torch.matmul(q, k.transpose(-1, -2))/ math.sqrt(q.shape[-1])\n",
    "print(\"attention_scores shape :\",attention_scores.shape)\n",
    "\n",
    "attention_mask=data[\"input_mask\"]\n",
    "attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "print(\"attention_mask shape :\",attention_mask.shape)\n",
    "\n",
    "attention_scores = attention_scores.masked_fill(attention_mask == 0, float('-inf'))\n",
    "\n",
    "# Normalize the attention scores to probabilities.\n",
    "attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "\n",
    "context_layer = torch.matmul(attention_probs, v)\n",
    "context_layer = context_layer.transpose(1, 2).contiguous().view(B, T, C) \n",
    "context_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9fa8daa-c19c-409d-8fec-a4ae2c3373af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertSelfAttention, self).__init__()\n",
    "        if config.hidden_size % config.num_attention_heads!= 0:\n",
    "            raise ValueError(\n",
    "                \"The hidden size (%d) is not a multiple of the number of attention heads (%d)\" % (\n",
    "                    config.hidden_size, config.num_attention_heads))\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
    "        self.hidden_size=config.hidden_size\n",
    "\n",
    "        self.query = nn.Linear(config.hidden_size, self.hidden_size)\n",
    "        self.key = nn.Linear(config.hidden_size, self.hidden_size)\n",
    "        self.value = nn.Linear(config.hidden_size, self.hidden_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
    "\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask):\n",
    "        B, T, C = hidden_states.size()\n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "        mixed_key_layer = self.key(hidden_states)\n",
    "        mixed_value_layer = self.value(hidden_states)\n",
    "        \n",
    "        query_layer = mixed_query_layer.view(B, T, self.num_attention_heads, C // self.num_attention_heads).transpose(1, 2) # (B, nh, T, hs)\n",
    "        key_layer = mixed_key_layer.view(B, T, self.num_attention_heads, C // self.num_attention_heads).transpose(1, 2) # (B, nh, T, hs)\n",
    "        value_layer = mixed_value_layer.view(B, T, self.num_attention_heads, C // self.num_attention_heads).transpose(1, 2) # (B, nh, T, hs)\n",
    "\n",
    "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "            attention_scores = attention_scores.masked_fill(attention_mask == 0, float('-inf'))\n",
    "\n",
    "        # Normalize the attention scores to probabilities.\n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.transpose(1, 2).contiguous().view(B, T, C) \n",
    "        return context_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ad09e8b-d260-40cd-89e8-8cf85bc215df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_mask shape torch.Size([8, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512, 768])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_mask=data[\"input_mask\"]\n",
    "print(\"input_mask shape\",input_mask.shape)\n",
    "attenModel=BertSelfAttention(config)\n",
    "x_att=attenModel(x_emb,input_mask)\n",
    "x_att.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd87e6f3-11ff-42a5-9277-0cb26941d853",
   "metadata": {},
   "source": [
    "## 3 attention +add&Norm\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"images/encoder_atten.png\" alt=\"Image\" style=\"width:300px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2be93223-e1b5-44b1-b8c1-aa31491b90bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSelfOutput(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertSelfOutput, self).__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "    def forward(self, hidden_states, input_tensor):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states\n",
    "\n",
    "class BertAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertAttention, self).__init__()\n",
    "        self.self = BertSelfAttention(config)\n",
    "        self.output = BertSelfOutput(config)\n",
    "\n",
    "    def forward(self, input_tensor, attention_mask):\n",
    "        self_output = self.self(input_tensor, attention_mask)\n",
    "        attention_output = self.output(self_output, input_tensor)\n",
    "        return attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "932e7a46-be34-419e-be6d-2581a4f2ab4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512, 768])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertAttModel=BertAttention(config)\n",
    "x_att=bertAttModel(x_emb,input_mask)\n",
    "x_att.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4f65fd-320d-4b58-bffe-be67099b6340",
   "metadata": {},
   "source": [
    "## 4 FFN层\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"images/encoder_mlp.png\" alt=\"Image\" style=\"width:300px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4bccf354-ce81-45d4-b075-b3e87c967318",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(FFN, self).__init__()\n",
    "        self.dense1 = nn.Linear(config.hidden_size, config.intermediate_size)        \n",
    "        self.dense2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        \n",
    "    def gelu(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden_states=x\n",
    "        hidden_states = self.dense1(hidden_states)\n",
    "        hidden_states = self.gelu(hidden_states)\n",
    "        hidden_states = self.dense2(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + x)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba9eb08c-0abd-4574-a1ea-7f3a60b22136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512, 768])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp=FFN(config)\n",
    "x_mlp=mlp(x_att)\n",
    "x_mlp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b53c126-afb0-42eb-916d-1d7ee22c6a83",
   "metadata": {},
   "source": [
    "## 4 Block层\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"images/encoder_block.png\" alt=\"Image\" style=\"width:300px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fae57363-1403-469b-ac53-bf48b14b378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLOCK 层\n",
    "class BertLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertLayer, self).__init__()\n",
    "        self.attention = BertAttention(config)\n",
    "        self.mlp = FFN(config)\n",
    "       \n",
    "    def forward(self, hidden_states, attention_mask):\n",
    "        attention_output = self.attention(hidden_states, attention_mask)\n",
    "        layer_output = self.mlp(attention_output)\n",
    "    \n",
    "        return layer_output\n",
    "\n",
    "# 多层BLOCK层\n",
    "class BertEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertEncoder, self).__init__()\n",
    "        self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask, output_all_encoded_layers=True):\n",
    "        all_encoder_layers = []\n",
    "        for layer_module in self.layer:\n",
    "            hidden_states = layer_module(hidden_states, attention_mask)\n",
    "            if output_all_encoded_layers:\n",
    "                all_encoder_layers.append(hidden_states)\n",
    "        if not output_all_encoded_layers:\n",
    "            all_encoder_layers.append(hidden_states)\n",
    "        return all_encoder_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d33d8bc-2bc1-4de6-8a85-0b567d3ad28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512, 768])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model=BertEncoder(config)\n",
    "x_bloks=bert_model(x_emb,input_mask)\n",
    "x_bloks[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ded1bc6-b23c-48a6-a410-3b3bf416600c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_bloks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8927b9b-c081-4345-8972-d8293f9539a6",
   "metadata": {},
   "source": [
    "## 5 CLS 输出层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "36f89150-22aa-4534-87c7-707b9e2f0c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertPooler(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertPooler, self).__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
    "        # to the first token.\n",
    "        first_token_tensor = hidden_states[:, 0]\n",
    "        pooled_output = self.dense(first_token_tensor)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8758e050-6dc4-4d3c-abf8-d93f567c182f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 768])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clsModel=BertPooler(config)\n",
    "x_cls=clsModel(x_bloks[-1])\n",
    "x_cls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "73863742-f71a-462c-9657-d0d87afa88c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 102267648\n",
      "torch.Size([8, 768]) torch.Size([8, 512, 768]) 12\n",
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(21128, 768)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (mlp): FFN(\n",
      "          (dense1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (dense2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class BertModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertModel, self).__init__()\n",
    "        self.embeddings = BertEmbeddings(config)\n",
    "        self.encoder = BertEncoder(config)\n",
    "        self.pooler = BertPooler(config)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None):\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones_like(input_ids)\n",
    "        embedding_output = self.embeddings(input_ids, token_type_ids)\n",
    "       \n",
    "        encoded_layers = self.encoder(embedding_output, attention_mask)\n",
    "        sequence_output = encoded_layers[-1]\n",
    "        pooled_output = self.pooler(sequence_output)\n",
    "        return pooled_output, sequence_output, encoded_layers\n",
    "\n",
    "bert_model = BertModel(config)\n",
    "# 假设你已经定义了你的模型 model\n",
    "total_params = sum(p.numel() for p in bert_model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "\n",
    "input_mask=data[\"input_mask\"]\n",
    "input_ids=data[\"input_ids\"]\n",
    "token_type_ids=data[\"segment_ids\"]\n",
    "pooled_output, sequence_output, encoded_layers=bert_model(input_ids,token_type_ids,input_mask)\n",
    "print(pooled_output.shape,sequence_output.shape,len(encoded_layers))\n",
    "print(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e5f1d-138e-420b-b9b3-f53b1c97a017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "torch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
